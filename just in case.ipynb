{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcc7489-d1d4-45bc-9215-aea370c11e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29632 images belonging to 4 classes.\n",
      "Found 12698 images belonging to 4 classes.\n",
      "Training samples: 29632\n",
      "Validation samples: 12698\n",
      "Class mapping: {'COVID': 0, 'Normal': 1, 'Viral Pneumonia': 2, 'Lung_Opacity': 3}\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_0.75_224_no_top.h5\n",
      "\u001b[1m5903360/5903360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Base model loaded with ImageNet weights\n",
      "\n",
      "Model Architecture:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'InputLayer' object has no attribute 'output_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 78\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel Architecture:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(model\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Output Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39moutput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mcount_params()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m total_params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcount_params()\n\u001b[0;32m     81\u001b[0m trainable_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mcount_params(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtrainable_weights])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'InputLayer' object has no attribute 'output_shape'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 4\n",
    "EPOCHS = 20\n",
    "\n",
    "# Dataset path\n",
    "data_dir = \"COVID-19_Radiography_Dataset\"\n",
    "classes = [\"COVID\", \"Normal\", \"Viral Pneumonia\", \"Lung_Opacity\"]\n",
    "\n",
    "# Question 2: Split data with stratified holdout (70% train, 30% validation)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=classes,\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=classes,\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Class mapping: {train_generator.class_indices}\")\n",
    "\n",
    "# Question 3-4: Import MobileNetV2 with ImageNet pretrained weights\n",
    "base_model = MobileNetV2(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "    alpha=0.75  # Using the x0.75 version as specified in the assignment\n",
    ")\n",
    "print(\"Base model loaded with ImageNet weights\")\n",
    "\n",
    "# Question 5: Replace the last layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Question 6-7: Display model architecture and parameters\n",
    "print(\"\\nModel Architecture:\")\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"Layer {i}: {layer.name}, Output Shape: {layer.output_shape}, Params: {layer.count_params()}\")\n",
    "\n",
    "total_params = model.count_params()\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_params = total_params - trainable_params\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "print(f\"Non-trainable parameters: {non_trainable_params}\")\n",
    "\n",
    "# Question 8: Retrain using transfer learning with different freezing strategies\n",
    "def train_and_evaluate(model, trainable_layers, strategy_name):\n",
    "    # Reset model weights for fair comparison\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel_initializer') and hasattr(layer, 'bias_initializer'):\n",
    "            layer.kernel.assign(layer.kernel_initializer(shape=layer.kernel.shape))\n",
    "            layer.bias.assign(layer.bias_initializer(shape=layer.bias.shape))\n",
    "    \n",
    "    # Freeze/unfreeze layers according to strategy\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Unfreeze specific layers based on the strategy\n",
    "    if trainable_layers > 0:\n",
    "        for layer in base_model.layers[-trainable_layers:]:\n",
    "            layer.trainable = True\n",
    "    \n",
    "    # Unfreeze FC layers\n",
    "    for layer in model.layers[len(base_model.layers):]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Recompile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(f\"\\nTraining with strategy: {strategy_name}\")\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // BATCH_SIZE\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Evaluate the model\n",
    "    validation_generator.reset()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(validation_generator.samples // BATCH_SIZE + 1):\n",
    "        X, y = next(validation_generator)\n",
    "        pred = model.predict(X)\n",
    "        y_true.extend(np.argmax(y, axis=1))\n",
    "        y_pred.extend(np.argmax(pred, axis=1))\n",
    "        if len(y_true) >= validation_generator.samples:\n",
    "            break\n",
    "    \n",
    "    # Trim to match validation samples exactly\n",
    "    y_true = y_true[:validation_generator.samples]\n",
    "    y_pred = y_pred[:validation_generator.samples]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    sensitivity = recall  # Same as recall for multi-class\n",
    "    \n",
    "    print(f\"Validation Metrics for {strategy_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "    \n",
    "    # Plot convergence curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Accuracy Curves - {strategy_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves - {strategy_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{strategy_name}_convergence.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "        'sensitivity': sensitivity,\n",
    "        'training_time': training_time,\n",
    "        'history': history.history\n",
    "    }\n",
    "\n",
    "# Run the three strategies (Question 8)\n",
    "results = {}\n",
    "\n",
    "# Strategy 1: Last two convolutional layers + three FC layers\n",
    "results['strategy1'] = train_and_evaluate(model, 2, \"Last 2 Conv + FC layers\")\n",
    "\n",
    "# Strategy 2: Last convolutional layer + three FC layers\n",
    "results['strategy2'] = train_and_evaluate(model, 1, \"Last 1 Conv + FC layers\")\n",
    "\n",
    "# Strategy 3: Only the last three FC layers\n",
    "results['strategy3'] = train_and_evaluate(model, 0, \"Only FC layers\")\n",
    "\n",
    "# Question 9: Compare results\n",
    "print(\"\\nComparison of Results:\")\n",
    "metrics = ['accuracy', 'recall', 'precision', 'f1', 'sensitivity', 'training_time']\n",
    "strategies = ['strategy1', 'strategy2', 'strategy3']\n",
    "strategy_names = [\"Last 2 Conv + FC layers\", \"Last 1 Conv + FC layers\", \"Only FC layers\"]\n",
    "\n",
    "# Create comparison table\n",
    "comparison = {}\n",
    "for metric in metrics:\n",
    "    comparison[metric] = [results[s][metric] for s in strategies]\n",
    "\n",
    "# Print comparison table\n",
    "print(\"\\n{:<20} {:<25} {:<25} {:<25}\".format('Metric', *strategy_names))\n",
    "print(\"-\" * 95)\n",
    "for metric in metrics:\n",
    "    if metric == 'training_time':\n",
    "        print(\"{:<20} {:<25.2f} {:<25.2f} {:<25.2f}\".format(\n",
    "            metric, *comparison[metric]\n",
    "        ))\n",
    "    else:\n",
    "        print(\"{:<20} {:<25.4f} {:<25.4f} {:<25.4f}\".format(\n",
    "            metric, *comparison[metric]\n",
    "        ))\n",
    "\n",
    "# Save the final model\n",
    "model.save('covid_xray_mobilenetv2_best.h5')\n",
    "print(\"\\nModel saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d822b3-dd54-4c83-8d33-5ce14c21144a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
